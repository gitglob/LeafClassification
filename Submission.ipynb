{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zhome/68/a/154632/Documents/dl/LeafClassification\n"
     ]
    }
   ],
   "source": [
    "cd ~/Documents/dl/LeafClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import data_utils\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from skimage import io\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "# from torchvision.nets.quantization import resnet50, ResNet50_QuantizedWeights\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GPU.\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataloaders and net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectItem(nn.Module):\n",
    "    def __init__(self, item_index):\n",
    "        super(SelectItem, self).__init__()\n",
    "        self._name = 'selectitem'\n",
    "        self.item_index = item_index\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return inputs[self.item_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafDataset(Dataset):\n",
    "    \"\"\"Leaf dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, train=False, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.leafs_df = pd.read_csv(csv_file)\n",
    "        self.data = self.leafs_df.values\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "\n",
    "        self.parse_data()\n",
    "\n",
    "    def parse_data(self):\n",
    "        self.ids = np.array(self.data[:, 0], dtype=int)\n",
    "        if self.train:\n",
    "            self.labels = pd.Categorical(pd.factorize(self.leafs_df.species)[0])\n",
    "            self.labels = np.array(self.labels)\n",
    "            self.label_dummies = pd.get_dummies(self.leafs_df.species)\n",
    "            self.label_dummies = np.array(self.label_dummies)\n",
    "            self.species = np.array(self.data[:, 1], dtype=str)\n",
    "            self.margins = np.array(self.data[:, 2:66], dtype=float)\n",
    "            self.shapes = np.array(self.data[:, 66:130], dtype=float)\n",
    "            self.textures = np.array(self.data[:, 130:], dtype=float)\n",
    "        if self.test:\n",
    "            self.labels = np.empty((len(self.data)), dtype=int)\n",
    "            self.label_dummies = np.empty((len(self.data), NUM_CLASSES), dtype=int)\n",
    "            self.species = np.empty((len(self.data)), dtype=str)\n",
    "            self.margins = np.array(self.data[:, 1:65], dtype=float)\n",
    "            self.shapes = np.array(self.data[:, 65:129], dtype=float)\n",
    "            self.textures = np.array(self.data[:, 129:], dtype=float)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.leafs_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the image\n",
    "        img_name = str(self.ids[idx]) + '.jpg'\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "\n",
    "        # no matter what happens, we need to padd all the images to the same dimensions, so that we can resize them without distorting them\n",
    "        image = data_utils.pad2square(image)  # Make the image square\n",
    "        image = resize(image, output_shape=(128, 128), mode='reflect', anti_aliasing=True)  # resizes the image\n",
    "\n",
    "        # augment the image if chosen to\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # get the other data\n",
    "        id_ = self.ids[idx]\n",
    "        margin = self.margins[idx]\n",
    "        shape = self.shapes[idx]\n",
    "        texture = self.textures[idx]\n",
    "        label = self.labels[idx]\n",
    "        label_dummy = self.label_dummies[idx]\n",
    "        specie = self.species[idx]\n",
    "            \n",
    "        return image, margin, shape, texture, label, label_dummy, specie, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = 'test.csv'\n",
    "root_dir = 'images/'\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "batch_size = 32\n",
    "testset = LeafDataset(test_csv, root_dir, transform=test_transform, train=False, test=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=768, bias=True)\n",
      "  )\n",
      "  (preprocess): ImageClassification(\n",
      "      crop_size=[224]\n",
      "      resize_size=[232]\n",
      "      mean=[0.485, 0.456, 0.406]\n",
      "      std=[0.229, 0.224, 0.225]\n",
      "      interpolation=InterpolationMode.BILINEAR\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (recurrent): Sequential(\n",
      "    (0): GRU(64, 128, num_layers=2)\n",
      "    (1): SelectItem()\n",
      "  )\n",
      "  (l_out): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=99, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "height, width, channels = 128,128,1\n",
    "\n",
    "# Keep track of features to output layer\n",
    "conv_feature_size = 768\n",
    "vector_input_size = 128\n",
    "vector_feature_size = 128\n",
    "rnn_input_size = 64 # must be the same as the x_shape channels\n",
    "rnn_feature_size = 128\n",
    "features_cat_size = 1024\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # prepare pretrained net - image\n",
    "        resnet_weights = ResNet50_Weights.DEFAULT\n",
    "        self.resnet = resnet50(weights=resnet_weights)\n",
    "        self.resnet.eval()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requiresGrad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, conv_feature_size)\n",
    "        self.preprocess = resnet_weights.transforms()\n",
    "\n",
    "        ## margin, texture\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=vector_input_size,\n",
    "                    out_features=vector_feature_size,\n",
    "                    bias=False),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "\n",
    "        # shape\n",
    "        self.recurrent = nn.Sequential(\n",
    "            nn.GRU(input_size=rnn_input_size,     # The number of expected features in the input x\n",
    "                    hidden_size=rnn_feature_size, # The number of features in the hidden state h\n",
    "                    num_layers=2),                # Number of recurrent layers\n",
    "            SelectItem(0)\n",
    "        )\n",
    "\n",
    "        # classification\n",
    "        self.l_out = nn.Sequential(\n",
    "            nn.Linear(in_features=features_cat_size,\n",
    "                        out_features=NUM_CLASSES,\n",
    "                        bias=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_img, x_margin, x_shape, x_texture = X\n",
    "        X_img = self.preprocess(X_img)\n",
    "        features = []\n",
    "\n",
    "        features_img = self.resnet(X_img)\n",
    "        features.append(features_img)\n",
    "\n",
    "        x = torch.cat((x_margin, x_texture), dim=1)  # if you want to use features as feature vectors\n",
    "        x = self.fc2(x)\n",
    "        features_vector = x\n",
    "        features.append(features_vector)\n",
    "        \n",
    "        features_rnn = self.recurrent(x_shape)\n",
    "        features.append(features_rnn)\n",
    "        \n",
    "        features_final = torch.cat(features, dim=1)\n",
    "        \n",
    "        out = self.l_out(features_final)\n",
    "        return out, F.softmax(out, dim=1)\n",
    "\n",
    "net = Net()\n",
    "net = net.float()\n",
    "if use_cuda:\n",
    "    net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"/zhome/68/a/154632/Documents/dl/LeafClassification/models/my_model.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission to Kaggle\n",
    "\n",
    "First we have to make test set predictions, then we have to place the output in the submission file and then upload to Kaggle to get our score! You can upload up to 5 submissions per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show intermediate results\n",
    "# Compute the val accuracy\n",
    "ids_test, preds_test = [], []\n",
    "net.eval()  # testing mode\n",
    "for (i, batch) in enumerate(test_loader):\n",
    "    # extract subfields\n",
    "    image, margins, shapes, textures, _, _, _, ids = batch\n",
    "    num = len(ids)\n",
    "    image = np.repeat(image, 3, axis=1)\n",
    "    \n",
    "    # convert to float and move to cuda\n",
    "    image = image.to(device).float()\n",
    "    margins = margins.to(device).float()\n",
    "    shapes = shapes.to(device).float()\n",
    "    textures = textures.to(device).float()\n",
    "\n",
    "    # split input and label\n",
    "    inputs = image, margins, shapes, textures\n",
    "\n",
    "    _, y_out = net(inputs)\n",
    "    y_out = y_out.detach().cpu().numpy()\n",
    "    # print(np.shape(y_out))\n",
    "\n",
    "    ids = ids.detach().cpu().numpy()\n",
    "    ids_test.extend(ids)\n",
    "    if i!=len(y_out):\n",
    "        # in case of the last batch, num will be less than batch_size\n",
    "        y_out = y_out[:num]\n",
    "    preds_test.append(y_out)\n",
    "    # print(np.shape(preds_test))\n",
    "\n",
    "preds_test = np.concatenate(preds_test, axis=0)\n",
    "# print(len(ids_test), ids_test)\n",
    "# print(len(preds_test), preds_test)\n",
    "\n",
    "assert len(ids_test) == len(preds_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>0.010518</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.009004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.010987</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>0.009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.009233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Acer_Capillipes  Acer_Circinatum  Acer_Mono  Acer_Opalus  \\\n",
       "0   4         0.009461         0.010169   0.008479     0.010233   \n",
       "1   7         0.010028         0.010686   0.008188     0.010322   \n",
       "2   9         0.009843         0.009203   0.008562     0.009201   \n",
       "3  12         0.010037         0.010876   0.009165     0.009888   \n",
       "4  13         0.009072         0.009492   0.009810     0.010342   \n",
       "\n",
       "   Acer_Palmatum  Acer_Pictum  Acer_Platanoids  Acer_Rubrum  Acer_Rufinerve  \\\n",
       "0       0.008833     0.010082         0.010518     0.009891        0.010216   \n",
       "1       0.008344     0.010944         0.009602     0.011802        0.009685   \n",
       "2       0.010173     0.010908         0.010285     0.010283        0.010202   \n",
       "3       0.009773     0.009631         0.009467     0.010347        0.010207   \n",
       "4       0.009651     0.009695         0.009900     0.009190        0.010184   \n",
       "\n",
       "   ...  Salix_Fragilis  Salix_Intergra  Sorbus_Aria  Tilia_Oliveri  \\\n",
       "0  ...        0.009742        0.010285     0.009651       0.011920   \n",
       "1  ...        0.010285        0.010338     0.009693       0.010183   \n",
       "2  ...        0.011597        0.011808     0.010987       0.009640   \n",
       "3  ...        0.009857        0.011638     0.010320       0.009680   \n",
       "4  ...        0.010130        0.011286     0.009196       0.011311   \n",
       "\n",
       "   Tilia_Platyphyllos  Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "0            0.009740         0.008265            0.009737        0.010058   \n",
       "1            0.011543         0.008781            0.009415        0.011010   \n",
       "2            0.011667         0.009608            0.008621        0.008901   \n",
       "3            0.011227         0.008964            0.009006        0.009370   \n",
       "4            0.009381         0.008373            0.010328        0.009733   \n",
       "\n",
       "   Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "0                      0.011304         0.009004  \n",
       "1                      0.011018         0.009893  \n",
       "2                      0.010974         0.009978  \n",
       "3                      0.011292         0.010055  \n",
       "4                      0.011071         0.009233  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame(preds_test, columns=data.le.classes_)\n",
    "ids_test_df = pd.DataFrame(ids_test, columns=[\"id\"])\n",
    "submission = pd.concat([ids_test_df, preds_df], axis=1)\n",
    "submission.to_csv(\"/zhome/68/a/154632/Documents/dl/LeafClassification/submissions/submission.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# below prints the submission, can be removed and replaced with code block below\n",
    "submission.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload submission\n",
    "\n",
    "1. Go to [`https://www.kaggle.com/c/leaf-classification/submit`](https://www.kaggle.com/c/leaf-classification/submit)\n",
    "3. Click or drop your submission here (writing a description is good practice)\n",
    "4. Submit and look at where you are on the leaderboard.\n",
    "\n",
    "Success! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
